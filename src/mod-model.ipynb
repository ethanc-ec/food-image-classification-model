{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732505210.716445   62740 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732505210.853979   62740 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/ds340-project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\" if Path.cwd().name == \"src\" else Path.cwd() / \"data\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5833228288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7176948942065291305\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732505233.998688   62740 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[1])\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75732 files belonging to 101 classes.\n",
      "Using 60586 files for training.\n",
      "Found 15150 files belonging to 101 classes.\n",
      "Using 3030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"mod_input\" / \"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"mod_input\" / \"valid\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 3)\n",
    "num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=input_shape, pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.layers[-1].output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(101, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 0.3474 - loss: 2.8690\n",
      "Epoch 1: val_accuracy improved from -inf to 0.59571, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m352s\u001b[0m 301ms/step - accuracy: 0.3475 - loss: 2.8686 - val_accuracy: 0.5957 - val_loss: 1.6475\n",
      "Epoch 2/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.5071 - loss: 1.9905\n",
      "Epoch 2: val_accuracy improved from 0.59571 to 0.63432, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 183ms/step - accuracy: 0.5071 - loss: 1.9904 - val_accuracy: 0.6343 - val_loss: 1.4535\n",
      "Epoch 3/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 184ms/step - accuracy: 0.5601 - loss: 1.7505\n",
      "Epoch 3: val_accuracy improved from 0.63432 to 0.64092, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m177s\u001b[0m 186ms/step - accuracy: 0.5601 - loss: 1.7505 - val_accuracy: 0.6409 - val_loss: 1.4067\n",
      "Epoch 4/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6002 - loss: 1.5538\n",
      "Epoch 4: val_accuracy improved from 0.64092 to 0.65875, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 190ms/step - accuracy: 0.6002 - loss: 1.5538 - val_accuracy: 0.6587 - val_loss: 1.3423\n",
      "Epoch 5/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6387 - loss: 1.3878\n",
      "Epoch 5: val_accuracy improved from 0.65875 to 0.66997, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 194ms/step - accuracy: 0.6387 - loss: 1.3878 - val_accuracy: 0.6700 - val_loss: 1.3040\n",
      "Epoch 6/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6714 - loss: 1.2431\n",
      "Epoch 6: val_accuracy did not improve from 0.66997\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m180s\u001b[0m 190ms/step - accuracy: 0.6714 - loss: 1.2431 - val_accuracy: 0.6660 - val_loss: 1.3176\n",
      "Epoch 7/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.6997 - loss: 1.1217\n",
      "Epoch 7: val_accuracy improved from 0.66997 to 0.67360, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 199ms/step - accuracy: 0.6997 - loss: 1.1217 - val_accuracy: 0.6736 - val_loss: 1.3259\n",
      "Epoch 8/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 0.7264 - loss: 1.0090\n",
      "Epoch 8: val_accuracy improved from 0.67360 to 0.67558, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m190s\u001b[0m 201ms/step - accuracy: 0.7264 - loss: 1.0089 - val_accuracy: 0.6756 - val_loss: 1.3456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8a6874a810>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINETUNE = True\n",
    "epochs = 20\n",
    "checkpoint_filepath = Path().cwd() / \"model_ckpts\" / \"mod_model.keras\"\n",
    "lr = 0.001\n",
    "\n",
    "if checkpoint_filepath.exists() and FINETUNE:\n",
    "    model = keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "    lr = 0.0002\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Model loaded from: {checkpoint_filepath}\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
