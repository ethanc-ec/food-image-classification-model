{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733148475.929968    1052 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733148476.169995    1052 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/ds340-project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\" if Path.cwd().name == \"src\" else Path.cwd() / \"data\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5833228288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 16402023003948573805\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733148519.756325    1052 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[1])\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75732 files belonging to 101 classes.\n",
      "Using 60586 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733148544.529990    1052 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15150 files belonging to 101 classes.\n",
      "Using 3030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"mod_input\" / \"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"mod_input\" / \"valid\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 3)\n",
    "num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=input_shape, pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.layers[-1].output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(101, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /workspaces/ds340-project/src/model_ckpts/mod_model.keras\n",
      "Fine-tuning model. New checkpoint: /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "New learning rate: 0.0002\n",
      "New training log: /workspaces/ds340-project/src/model_training_performance/mod_model_fine_training.log\n",
      "Epoch 1/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 0.3380 - loss: 2.9525\n",
      "Epoch 1: val_accuracy improved from -inf to 0.58251, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 216ms/step - accuracy: 0.3380 - loss: 2.9520 - val_accuracy: 0.5825 - val_loss: 1.6891\n",
      "Epoch 2/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.4915 - loss: 2.0649\n",
      "Epoch 2: val_accuracy improved from 0.58251 to 0.62277, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 171ms/step - accuracy: 0.4915 - loss: 2.0649 - val_accuracy: 0.6228 - val_loss: 1.5040\n",
      "Epoch 3/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.5481 - loss: 1.7934\n",
      "Epoch 3: val_accuracy improved from 0.62277 to 0.64257, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 166ms/step - accuracy: 0.5481 - loss: 1.7934 - val_accuracy: 0.6426 - val_loss: 1.4232\n",
      "Epoch 4/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.5927 - loss: 1.5982\n",
      "Epoch 4: val_accuracy improved from 0.64257 to 0.65380, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 169ms/step - accuracy: 0.5927 - loss: 1.5982 - val_accuracy: 0.6538 - val_loss: 1.3783\n",
      "Epoch 5/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6286 - loss: 1.4375\n",
      "Epoch 5: val_accuracy improved from 0.65380 to 0.66337, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 169ms/step - accuracy: 0.6287 - loss: 1.4375 - val_accuracy: 0.6634 - val_loss: 1.3365\n",
      "Epoch 6/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.6610 - loss: 1.2936\n",
      "Epoch 6: val_accuracy improved from 0.66337 to 0.66997, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 169ms/step - accuracy: 0.6610 - loss: 1.2935 - val_accuracy: 0.6700 - val_loss: 1.3245\n",
      "Epoch 7/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.6906 - loss: 1.1661\n",
      "Epoch 7: val_accuracy did not improve from 0.66997\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 171ms/step - accuracy: 0.6906 - loss: 1.1660 - val_accuracy: 0.6647 - val_loss: 1.3545\n",
      "Epoch 8/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7167 - loss: 1.0491\n",
      "Epoch 8: val_accuracy improved from 0.66997 to 0.67294, saving model to /workspaces/ds340-project/src/model_ckpts/mod_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 176ms/step - accuracy: 0.7167 - loss: 1.0490 - val_accuracy: 0.6729 - val_loss: 1.3386\n",
      "Epoch 9/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7463 - loss: 0.9386\n",
      "Epoch 9: val_accuracy did not improve from 0.67294\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 173ms/step - accuracy: 0.7463 - loss: 0.9386 - val_accuracy: 0.6601 - val_loss: 1.4156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f6f95b92610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINETUNE = True\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "model_name = \"mod_model\"\n",
    "checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}.keras\"\n",
    "training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_training.log\"\n",
    "\n",
    "if checkpoint_filepath.exists() and FINETUNE:\n",
    "    model = keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "    lr = 0.0002\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Model loaded from: {checkpoint_filepath}\")\n",
    "\n",
    "    checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}_fine.keras\"\n",
    "    training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_fine_training.log\"\n",
    "    \n",
    "    print(f\"Fine-tuning model. New checkpoint: {checkpoint_filepath}\")\n",
    "    print(f\"New learning rate: {lr}\")\n",
    "    print(f\"New training log: {training_log}\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    CSVLogger(\n",
    "        filename=training_log, \n",
    "        separator=',', \n",
    "        append=False\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
