{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732298375.076176   77935 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732298375.079861   77935 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/ds340-project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\" if Path.cwd().name == \"src\" else Path.cwd() / \"data\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5833228288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 9311826414884405339\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732298410.107232   77935 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[1])\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75736 files belonging to 101 classes.\n",
      "Using 60589 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732298434.274495   77935 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15150 files belonging to 101 classes.\n",
      "Using 3030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"base_input\" / \"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"base_input\" / \"valid\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "# test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "#     DATA_PATH / \"nobg_input\" / \"test\",\n",
    "#     validation_split=0.2,\n",
    "#     subset=\"validation\",\n",
    "#     seed=340,\n",
    "#     image_size=image_size,\n",
    "#     batch_size=batch_size,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 3)\n",
    "num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)\n",
    "# test_ds = test_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=input_shape, pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.layers[-1].output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(101, activation='softmax')(x)\n",
    "# output = layers.Dense(101, activation='softmax')(base_model.layers[-1].output)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 0.4430 - loss: 2.4264\n",
      "Epoch 1: val_accuracy improved from -inf to 0.76304, saving model to /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m265s\u001b[0m 214ms/step - accuracy: 0.4431 - loss: 2.4259 - val_accuracy: 0.7630 - val_loss: 0.9119\n",
      "Epoch 2/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6355 - loss: 1.3731\n",
      "Epoch 2: val_accuracy improved from 0.76304 to 0.77426, saving model to /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 167ms/step - accuracy: 0.6355 - loss: 1.3731 - val_accuracy: 0.7743 - val_loss: 0.8046\n",
      "Epoch 3/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.6897 - loss: 1.1427\n",
      "Epoch 3: val_accuracy improved from 0.77426 to 0.80528, saving model to /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 166ms/step - accuracy: 0.6897 - loss: 1.1427 - val_accuracy: 0.8053 - val_loss: 0.7125\n",
      "Epoch 4/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.7331 - loss: 0.9594\n",
      "Epoch 4: val_accuracy improved from 0.80528 to 0.81023, saving model to /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 164ms/step - accuracy: 0.7331 - loss: 0.9594 - val_accuracy: 0.8102 - val_loss: 0.6993\n",
      "Epoch 5/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.7648 - loss: 0.8362\n",
      "Epoch 5: val_accuracy did not improve from 0.81023\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 195ms/step - accuracy: 0.7648 - loss: 0.8362 - val_accuracy: 0.8083 - val_loss: 0.6773\n",
      "Epoch 6/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7942 - loss: 0.7178\n",
      "Epoch 6: val_accuracy improved from 0.81023 to 0.81650, saving model to /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 169ms/step - accuracy: 0.7942 - loss: 0.7178 - val_accuracy: 0.8165 - val_loss: 0.6682\n",
      "Epoch 7/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8182 - loss: 0.6177\n",
      "Epoch 7: val_accuracy did not improve from 0.81650\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 167ms/step - accuracy: 0.8182 - loss: 0.6176 - val_accuracy: 0.8129 - val_loss: 0.6946\n",
      "Epoch 8/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8409 - loss: 0.5382\n",
      "Epoch 8: val_accuracy did not improve from 0.81650\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 165ms/step - accuracy: 0.8409 - loss: 0.5381 - val_accuracy: 0.8132 - val_loss: 0.7014\n",
      "Epoch 9/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8599 - loss: 0.4669\n",
      "Epoch 9: val_accuracy did not improve from 0.81650\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 162ms/step - accuracy: 0.8600 - loss: 0.4668 - val_accuracy: 0.8142 - val_loss: 0.7385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f90a5e63e50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINETUNE = True\n",
    "epochs = 20\n",
    "checkpoint_filepath = Path().cwd() / \"model_ckpts\" / \"base_model.keras\"\n",
    "lr = 0.001\n",
    "\n",
    "if checkpoint_filepath.exists() and FINETUNE:\n",
    "    model = keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "    lr = 0.0002\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Model loaded from: {checkpoint_filepath}\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "] \n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
