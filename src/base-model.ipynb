{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733105706.970781   14530 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733105707.113871   14530 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/ds340-project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\" if Path.cwd().name == \"src\" else Path.cwd() / \"data\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5833228288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7467127724095977599\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733105728.882906   14530 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[1])\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75736 files belonging to 101 classes.\n",
      "Using 60589 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733105755.980196   14530 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15150 files belonging to 101 classes.\n",
      "Using 3030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"base_input\" / \"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"base_input\" / \"valid\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 3)\n",
    "num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=input_shape, pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.layers[-1].output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(101, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /workspaces/ds340-project/src/model_ckpts/base_model.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.4351 - loss: 2.5125\n",
      "Epoch 1: val_accuracy improved from -inf to 0.75182, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 218ms/step - accuracy: 0.4352 - loss: 2.5119 - val_accuracy: 0.7518 - val_loss: 0.9544\n",
      "Epoch 2/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6377 - loss: 1.3786\n",
      "Epoch 2: val_accuracy improved from 0.75182 to 0.78086, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 180ms/step - accuracy: 0.6377 - loss: 1.3786 - val_accuracy: 0.7809 - val_loss: 0.8017\n",
      "Epoch 3/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.6863 - loss: 1.1565\n",
      "Epoch 3: val_accuracy improved from 0.78086 to 0.79175, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m179s\u001b[0m 189ms/step - accuracy: 0.6863 - loss: 1.1564 - val_accuracy: 0.7917 - val_loss: 0.7319\n",
      "Epoch 4/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7304 - loss: 0.9811\n",
      "Epoch 4: val_accuracy improved from 0.79175 to 0.80000, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 183ms/step - accuracy: 0.7304 - loss: 0.9810 - val_accuracy: 0.8000 - val_loss: 0.7054\n",
      "Epoch 5/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.7627 - loss: 0.8514\n",
      "Epoch 5: val_accuracy improved from 0.80000 to 0.80429, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 179ms/step - accuracy: 0.7627 - loss: 0.8514 - val_accuracy: 0.8043 - val_loss: 0.6879\n",
      "Epoch 6/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7888 - loss: 0.7351\n",
      "Epoch 6: val_accuracy improved from 0.80429 to 0.81155, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 174ms/step - accuracy: 0.7888 - loss: 0.7351 - val_accuracy: 0.8116 - val_loss: 0.6943\n",
      "Epoch 7/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.8122 - loss: 0.6362\n",
      "Epoch 7: val_accuracy improved from 0.81155 to 0.81353, saving model to /workspaces/ds340-project/src/model_ckpts/base_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 171ms/step - accuracy: 0.8122 - loss: 0.6362 - val_accuracy: 0.8135 - val_loss: 0.7035\n",
      "Epoch 8/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 0.8364 - loss: 0.5527\n",
      "Epoch 8: val_accuracy did not improve from 0.81353\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m187s\u001b[0m 198ms/step - accuracy: 0.8364 - loss: 0.5526 - val_accuracy: 0.8122 - val_loss: 0.7093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fa6af7e02d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINETUNE = True\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "model_name = \"base_model\"\n",
    "checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}.keras\"\n",
    "training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_training.log\"\n",
    "\n",
    "if checkpoint_filepath.exists() and FINETUNE:\n",
    "    model = keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "    lr = 0.0002\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Model loaded from: {checkpoint_filepath}\")\n",
    "\n",
    "    checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}_fine.keras\"\n",
    "    training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_fine_training.log\"\n",
    "    \n",
    "    print(f\"Fine-tuning model. New checkpoint: {checkpoint_filepath}\")\n",
    "    print(f\"New learning rate: {lr}\")\n",
    "    print(f\"New training log: {training_log}\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    CSVLogger(\n",
    "        filename=training_log, \n",
    "        separator=',', \n",
    "        append=False\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
