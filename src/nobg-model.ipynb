{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733108101.753222   43006 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733108101.862188   43006 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/workspaces/ds340-project/data')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import logging\n",
    "logger = tf.get_logger()\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "DATA_PATH = Path.cwd().parent / \"data\" if Path.cwd().name == \"src\" else Path.cwd() / \"data\"\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 5833228288\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 17317705679106634145\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733108124.700817   43006 gpu_device.cc:2022] Created device /device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.config import list_physical_devices\n",
    "print(\"Num GPUs Available: \", len(list_physical_devices('GPU')))\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices()[1])\n",
    "\n",
    "tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[1], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75732 files belonging to 101 classes.\n",
      "Using 60586 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733108146.804859   43006 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15150 files belonging to 101 classes.\n",
      "Using 3030 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size = (224, 224)\n",
    "batch_size = 64\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"nobg_input\" / \"train\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    DATA_PATH / \"nobg_input\" / \"valid\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=340,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (*image_size, 3)\n",
    "num_classes = 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(image, label):\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from keras.models import Model\n",
    "\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=input_shape, pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.layers[-1].output)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(101, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from: /workspaces/ds340-project/src/model_ckpts/nobg_model.keras\n",
      "Epoch 1/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 0.3796 - loss: 2.7274\n",
      "Epoch 1: val_accuracy improved from -inf to 0.62409, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m258s\u001b[0m 214ms/step - accuracy: 0.3797 - loss: 2.7270 - val_accuracy: 0.6241 - val_loss: 1.4896\n",
      "Epoch 2/20\n",
      "\u001b[1m944/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 0.5374 - loss: 1.8521\n",
      "Epoch 2: val_accuracy improved from 0.62409 to 0.66865, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 200ms/step - accuracy: 0.5374 - loss: 1.8519 - val_accuracy: 0.6686 - val_loss: 1.3280\n",
      "Epoch 3/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 0.5912 - loss: 1.6204\n",
      "Epoch 3: val_accuracy improved from 0.66865 to 0.68416, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 239ms/step - accuracy: 0.5912 - loss: 1.6203 - val_accuracy: 0.6842 - val_loss: 1.2376\n",
      "Epoch 4/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 0.6318 - loss: 1.4390\n",
      "Epoch 4: val_accuracy improved from 0.68416 to 0.68779, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m212s\u001b[0m 224ms/step - accuracy: 0.6318 - loss: 1.4390 - val_accuracy: 0.6878 - val_loss: 1.2320\n",
      "Epoch 5/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280ms/step - accuracy: 0.6641 - loss: 1.2819\n",
      "Epoch 5: val_accuracy improved from 0.68779 to 0.68845, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m273s\u001b[0m 288ms/step - accuracy: 0.6642 - loss: 1.2818 - val_accuracy: 0.6884 - val_loss: 1.1873\n",
      "Epoch 6/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.6955 - loss: 1.1502\n",
      "Epoch 6: val_accuracy improved from 0.68845 to 0.69109, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 291ms/step - accuracy: 0.6955 - loss: 1.1501 - val_accuracy: 0.6911 - val_loss: 1.1914\n",
      "Epoch 7/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 351ms/step - accuracy: 0.7203 - loss: 1.0415\n",
      "Epoch 7: val_accuracy improved from 0.69109 to 0.69934, saving model to /workspaces/ds340-project/src/model_ckpts/nobg_model_fine.keras\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m339s\u001b[0m 358ms/step - accuracy: 0.7203 - loss: 1.0414 - val_accuracy: 0.6993 - val_loss: 1.1792\n",
      "Epoch 8/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.7429 - loss: 0.9435\n",
      "Epoch 8: val_accuracy did not improve from 0.69934\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 404ms/step - accuracy: 0.7429 - loss: 0.9435 - val_accuracy: 0.6914 - val_loss: 1.2006\n",
      "Epoch 9/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406ms/step - accuracy: 0.7686 - loss: 0.8404\n",
      "Epoch 9: val_accuracy did not improve from 0.69934\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 411ms/step - accuracy: 0.7686 - loss: 0.8404 - val_accuracy: 0.6983 - val_loss: 1.2705\n",
      "Epoch 10/20\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.7880 - loss: 0.7629\n",
      "Epoch 10: val_accuracy did not improve from 0.69934\n",
      "\u001b[1m947/947\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m469s\u001b[0m 496ms/step - accuracy: 0.7880 - loss: 0.7629 - val_accuracy: 0.6950 - val_loss: 1.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe5f40e9850>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FINETUNE = True\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "model_name = \"nobg_model\"\n",
    "checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}.keras\"\n",
    "training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_training.log\"\n",
    "\n",
    "if checkpoint_filepath.exists() and FINETUNE:\n",
    "    model = keras.models.load_model(checkpoint_filepath, compile=False)\n",
    "    lr = 0.0002\n",
    "    \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    print(f\"Model loaded from: {checkpoint_filepath}\")\n",
    "\n",
    "    checkpoint_filepath = Path().cwd() / \"model_ckpts\" / f\"{model_name}_fine.keras\"\n",
    "    training_log = Path().cwd() / \"model_training_performance\" / f\"{model_name}_fine_training.log\"\n",
    "    \n",
    "    print(f\"Fine-tuning model. New checkpoint: {checkpoint_filepath}\")\n",
    "    print(f\"New learning rate: {lr}\")\n",
    "    print(f\"New training log: {training_log}\")\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=lr), metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss', \n",
    "        patience=3\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        filepath=checkpoint_filepath,\n",
    "        save_weights_only=False,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    CSVLogger(\n",
    "        filename=training_log, \n",
    "        separator=',', \n",
    "        append=False\n",
    "    )\n",
    "]\n",
    "\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
